"""
RAG è´¨é‡æµ‹è¯•è„šæœ¬
éªŒè¯å‘é‡åŒ–ç»“æœå’Œæ£€ç´¢æ€§èƒ½

ä½¿ç”¨æ–¹æ³•:
    python test_rag_quality.py
"""

import os
import time
from dotenv import load_dotenv
from rag_utils import get_rag_instance

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_vectordb_stats():
    """æµ‹è¯•å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯"""
    print("=" * 60)
    print("ğŸ“Š å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 60)
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° DASHSCOPE_API_KEY")
        return
    
    rag = get_rag_instance("db5_qwen", api_key)
    stats = rag.get_stats()
    
    print(f"\nâœ… å‘é‡åº“è·¯å¾„: {stats['persist_directory']}")
    print(f"âœ… åµŒå…¥æ¨¡å‹: {stats['embedding_model']}")
    print(f"âœ… æ–‡æ¡£æ•°é‡: {stats['total_documents']}")
    print()

def test_retrieval_quality(lambda_mult=0.3):
    """æµ‹è¯•æ£€ç´¢è´¨é‡ - åŸºç¡€åœºæ™¯"""
    print("=" * 60)
    print(f"ğŸ§ª æ£€ç´¢è´¨é‡æµ‹è¯• - åŸºç¡€åœºæ™¯ (lambda_mult={lambda_mult})")
    print("=" * 60)
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    rag = get_rag_instance("db5_qwen", api_key)
    
    # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
    test_queries = [
        {
            "query": "What is Zino's Petrel?",
            "expected_keywords": ["petrel", "bird", "seabird", "Pterodroma"],
            "complexity": "simple"
        },
        {
            "query": "Where does Zino's Petrel nest and what is its habitat?",
            "expected_keywords": ["nest", "habitat", "mountains", "Madeira"],
            "complexity": "medium"
        },
        {
            "query": "Describe the conservation status and main threats to Zino's Petrel, and what actions are being taken to protect the species?",
            "expected_keywords": ["conservation", "endangered", "threats", "protection"],
            "complexity": "complex"
        }
    ]
    
    for i, test in enumerate(test_queries, 1):
        print(f"\n{'=' * 60}")
        print(f"æµ‹è¯• {i}: {test['complexity'].upper()} æŸ¥è¯¢")
        print(f"{'=' * 60}")
        print(f"ğŸ“ æŸ¥è¯¢: '{test['query']}'")
        print(f"ğŸ¯ é¢„æœŸå…³é”®è¯: {', '.join(test['expected_keywords'])}")
        
        # è®¡æ—¶
        start_time = time.time()
        docs = rag.retrieve(test['query'], lambda_mult=lambda_mult)
        elapsed_time = time.time() - start_time
        
        print(f"\nâ±ï¸  æ£€ç´¢è€—æ—¶: {elapsed_time:.3f} ç§’")
        print(f"ğŸ“„ è¿”å›æ–‡æ¡£æ•°: {len(docs)}")
        
        # æ£€æŸ¥å…³é”®è¯è¦†ç›–
        all_content = " ".join([doc.page_content.lower() for doc in docs])
        found_keywords = [kw for kw in test['expected_keywords'] if kw.lower() in all_content]
        coverage = len(found_keywords) / len(test['expected_keywords']) * 100
        
        print(f"âœ… å…³é”®è¯è¦†ç›–ç‡: {coverage:.1f}% ({len(found_keywords)}/{len(test['expected_keywords'])})")
        print(f"   æ‰¾åˆ°: {', '.join(found_keywords) if found_keywords else 'æ— '}")
        
        # æ˜¾ç¤ºæ–‡æ¡£æ¥æº
        print(f"\nğŸ“š æ–‡æ¡£æ¥æº:")
        for j, doc in enumerate(docs, 1):
            source = doc.metadata.get('source_file', 'Unknown')
            page = doc.metadata.get('page', 'N/A')
            preview = doc.page_content[:100].replace('\n', ' ')
            print(f"   {j}. {source} (é¡µ {page})")
            print(f"      é¢„è§ˆ: {preview}...")
        
        # è´¨é‡è¯„ä¼°
        if coverage >= 75:
            print(f"\nâœ… è´¨é‡è¯„ä¼°: ä¼˜ç§€ï¼ˆè¦†ç›–ç‡ â‰¥75%ï¼‰")
        elif coverage >= 50:
            print(f"\nâš ï¸  è´¨é‡è¯„ä¼°: è‰¯å¥½ï¼ˆè¦†ç›–ç‡ â‰¥50%ï¼‰")
        else:
            print(f"\nâŒ è´¨é‡è¯„ä¼°: éœ€æ”¹è¿›ï¼ˆè¦†ç›–ç‡ <50%ï¼‰")

def test_user_scenarios(lambda_mult=0.3):
    """æµ‹è¯•ç”¨æˆ·å®é™…åœºæ™¯"""
    print("\n" + "=" * 60)
    print(f"ğŸ‘¥ ç”¨æˆ·å®é™…åœºæ™¯æµ‹è¯• (lambda_mult={lambda_mult})")
    print("=" * 60)
    print("æ¨¡æ‹ŸçœŸå®ç”¨æˆ·å¯¹è¯ï¼Œæµ‹è¯• RAG ç³»ç»Ÿçš„å®é™…è¡¨ç°")
    print()
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    rag = get_rag_instance("db5_qwen", api_key)
    
    # ç”¨æˆ·å®é™…æµ‹è¯•é—®é¢˜
    user_tests = [
        {
            "id": 1,
            "query": "Hi, how are you doing today?",
            "category": "é—®å€™",
            "expected_keywords": ["petrel", "bird", "fine", "good"],
            "expected_sticker": None,
            "expected_score_change": "+1 (empathy)"
        },
        {
            "id": 2,
            "query": "Where do you usually have your nesting areas?",
            "category": "æ –æ¯åœ°",
            "expected_keywords": ["nest", "Madeira", "mountains", "cliffs", "caves"],
            "expected_sticker": "ğŸ¡ Home",
            "expected_score_change": "+1 (knowledge)"
        },
        {
            "id": 3,
            "query": "How long do you live approximately?",
            "category": "å¯¿å‘½",
            "expected_keywords": ["years", "lifespan", "live", "age"],
            "expected_sticker": None,
            "expected_score_change": "+1 (deep_interaction)"
        },
        {
            "id": 4,
            "query": "Why do you need to abort sometimes to protect your species, that's a very sad thing and I don't quite understand how does it help you",
            "category": "ä¿æŠ¤ç­–ç•¥",
            "expected_keywords": ["conservation", "protection", "breeding", "survival", "predators"],
            "expected_sticker": "ğŸŒ± Helper (å¯èƒ½)",
            "expected_score_change": "+1 (conservation_action/empathy)"
        },
        {
            "id": 5,
            "query": "How long do you sleep?",
            "category": "æ—¥å¸¸ä¹ æƒ¯",
            "expected_keywords": ["sleep", "rest", "night", "day", "active"],
            "expected_sticker": "ğŸŒ™ Routine (å¯èƒ½)",
            "expected_score_change": "+1 (knowledge)"
        },
        {
            "id": 6,
            "query": "How do I find you?",
            "category": "è§‚å¯ŸæŒ‡å—",
            "expected_keywords": ["Madeira", "mountains", "sea", "observation", "location"],
            "expected_sticker": "ğŸ¡ Home (å¦‚æœªè§¦å‘)",
            "expected_score_change": "+1 (personal_engagement)"
        },
        {
            "id": 7,
            "query": "Do you have a friend?",
            "category": "ç¤¾äº¤",
            "expected_keywords": ["mate", "colony", "pair", "social", "alone"],
            "expected_sticker": None,
            "expected_score_change": "+1 (personal_engagement)"
        },
        {
            "id": 8,
            "query": "What do you eat for food and how do you catch it?",
            "category": "é¥®é£Ÿ",
            "expected_keywords": ["fish", "squid", "food", "catch", "hunt", "sea"],
            "expected_sticker": "ğŸ½ï¸ Food",
            "expected_score_change": "+1 (knowledge)"
        },
        {
            "id": 9,
            "query": "How can I help you and your species thrive?",
            "category": "ä¿æŠ¤è¡ŒåŠ¨",
            "expected_keywords": ["help", "protect", "conservation", "support", "habitat"],
            "expected_sticker": "ğŸŒ± Helper",
            "expected_score_change": "+1 (conservation_action)"
        }
    ]
    
    total_coverage = 0
    successful_tests = 0
    
    for test in user_tests:
        print(f"\n{'=' * 60}")
        print(f"æµ‹è¯• {test['id']}: {test['category']} - {test['expected_sticker'] or 'æ— è´´çº¸'}")
        print(f"{'=' * 60}")
        print(f"ğŸ“ é—®é¢˜: '{test['query']}'")
        print(f"ğŸ¯ é¢„æœŸå…³é”®è¯: {', '.join(test['expected_keywords'])}")
        print(f"ğŸ é¢„æœŸè´´çº¸: {test['expected_sticker'] or 'æ— '}")
        print(f"â¤ï¸  é¢„æœŸè¯„åˆ†: {test['expected_score_change']}")
        
        # è®¡æ—¶
        start_time = time.time()
        docs = rag.retrieve(test['query'], lambda_mult=lambda_mult)
        elapsed_time = time.time() - start_time
        
        print(f"\nâ±ï¸  æ£€ç´¢è€—æ—¶: {elapsed_time:.3f} ç§’")
        print(f"ğŸ“„ è¿”å›æ–‡æ¡£æ•°: {len(docs)}")
        
        # æ£€æŸ¥å…³é”®è¯è¦†ç›–
        all_content = " ".join([doc.page_content.lower() for doc in docs])
        found_keywords = [kw for kw in test['expected_keywords'] if kw.lower() in all_content]
        coverage = len(found_keywords) / len(test['expected_keywords']) * 100 if test['expected_keywords'] else 0
        total_coverage += coverage
        
        print(f"âœ… å…³é”®è¯è¦†ç›–ç‡: {coverage:.1f}% ({len(found_keywords)}/{len(test['expected_keywords'])})")
        if found_keywords:
            print(f"   æ‰¾åˆ°: {', '.join(found_keywords)}")
        else:
            print(f"   æ‰¾åˆ°: æ— ")
        
        # æ˜¾ç¤ºæ–‡æ¡£æ¥æºï¼ˆæœ€å¤šæ˜¾ç¤º 2 ä¸ªï¼‰
        print(f"\nğŸ“š æ–‡æ¡£æ¥æº:")
        for i, doc in enumerate(docs[:2], 1):
            source = doc.metadata.get('source_file', 'Unknown')
            page = doc.metadata.get('page', 'N/A')
            preview = doc.page_content[:80].replace('\n', ' ')
            print(f"   {i}. {source} (é¡µ {page})")
            print(f"      é¢„è§ˆ: {preview}...")
        
        # è´¨é‡è¯„ä¼°
        if coverage >= 60:
            print(f"\nâœ… æ£€ç´¢è´¨é‡: ä¼˜ç§€ï¼ˆè¦†ç›–ç‡ â‰¥60%ï¼‰")
            successful_tests += 1
        elif coverage >= 40:
            print(f"\nâš ï¸  æ£€ç´¢è´¨é‡: è‰¯å¥½ï¼ˆè¦†ç›–ç‡ â‰¥40%ï¼‰")
            successful_tests += 1
        else:
            print(f"\nâŒ æ£€ç´¢è´¨é‡: éœ€æ”¹è¿›ï¼ˆè¦†ç›–ç‡ <40%ï¼‰")
    
    # æ€»ç»“
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š æµ‹è¯•æ€»ç»“")
    print(f"{'=' * 60}")
    print(f"âœ… æˆåŠŸæµ‹è¯•: {successful_tests}/{len(user_tests)} ({successful_tests/len(user_tests)*100:.1f}%)")
    print(f"ğŸ“ˆ å¹³å‡å…³é”®è¯è¦†ç›–ç‡: {total_coverage/len(user_tests):.1f}%")
    
    if successful_tests >= 7:
        print(f"\nğŸ‰ æ•´ä½“è¯„ä¼°: ä¼˜ç§€ï¼RAG ç³»ç»Ÿè¡¨ç°å‡ºè‰²")
    elif successful_tests >= 5:
        print(f"\nğŸ‘ æ•´ä½“è¯„ä¼°: è‰¯å¥½ï¼ŒåŸºæœ¬æ»¡è¶³éœ€æ±‚")
    else:
        print(f"\nâš ï¸  æ•´ä½“è¯„ä¼°: éœ€è¦ä¼˜åŒ–ï¼Œå»ºè®®è°ƒæ•´æ£€ç´¢å‚æ•°")

def test_performance():
    """æµ‹è¯•æ€§èƒ½ï¼ˆç¼“å­˜æ•ˆæœï¼‰"""
    print("\n" + "=" * 60)
    print("âš¡ æ€§èƒ½æµ‹è¯•ï¼ˆç¼“å­˜æ•ˆæœï¼‰")
    print("=" * 60)
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    test_query = "What is Zino's Petrel?"
    
    # é¦–æ¬¡æŸ¥è¯¢ï¼ˆå†·å¯åŠ¨ï¼‰
    print(f"\nğŸ”µ é¦–æ¬¡æŸ¥è¯¢ï¼ˆå†·å¯åŠ¨ï¼‰...")
    start_time = time.time()
    rag1 = get_rag_instance("db5_qwen", api_key)
    docs1 = rag1.retrieve(test_query)
    cold_time = time.time() - start_time
    print(f"   â±ï¸  è€—æ—¶: {cold_time:.3f} ç§’")
    
    # ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    print(f"\nğŸŸ¢ ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰...")
    start_time = time.time()
    rag2 = get_rag_instance("db5_qwen", api_key)
    docs2 = rag2.retrieve(test_query)
    hot_time = time.time() - start_time
    print(f"   â±ï¸  è€—æ—¶: {hot_time:.3f} ç§’")
    
    # æ€§èƒ½æå‡
    speedup = cold_time / hot_time if hot_time > 0 else float('inf')
    print(f"\nğŸ“Š æ€§èƒ½æå‡: {speedup:.1f}x")
    print(f"   ğŸ”¹ å†·å¯åŠ¨: {cold_time:.3f} ç§’")
    print(f"   ğŸ”¹ ç¼“å­˜å‘½ä¸­: {hot_time:.3f} ç§’")

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ğŸ§ª RAG è´¨é‡æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    print()
    
    # 1. ç»Ÿè®¡ä¿¡æ¯
    test_vectordb_stats()
    
    # 2. åŸºç¡€æ£€ç´¢è´¨é‡æµ‹è¯•
    test_retrieval_quality()
    
    # 3. ç”¨æˆ·å®é™…åœºæ™¯æµ‹è¯•ï¼ˆæ–°å¢ï¼‰
    test_user_scenarios()
    
    # 4. æ€§èƒ½æµ‹è¯•
    test_performance()
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("=" * 60)
    print("\nğŸ’¡ æç¤º:")
    print("   - å¦‚æœå…³é”®è¯è¦†ç›–ç‡ <40%ï¼Œå»ºè®®è°ƒæ•´ lambda_mult å‚æ•°")
    print("   - å¦‚æœæ£€ç´¢é€Ÿåº¦ >3ç§’ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– API é…é¢")
    print("   - è¿è¡Œ 'streamlit run main.py' è¿›è¡Œå®é™…æµ‹è¯•")
    print()

if __name__ == "__main__":
    main()

